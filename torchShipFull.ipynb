{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import mnist\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import torch.nn.utils.prune as prune\n",
    "from torchinfo import summary\n",
    "from torch.nn.parameter import Parameter\n",
    "import random\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Net                                      --\n",
       "├─Linear: 1-1                            100\n",
       "├─Sigmoid: 1-2                           --\n",
       "├─Linear: 1-3                            420\n",
       "├─Sigmoid: 1-4                           --\n",
       "├─Linear: 1-5                            420\n",
       "├─Sigmoid: 1-6                           --\n",
       "├─Linear: 1-7                            21\n",
       "=================================================================\n",
       "Total params: 961\n",
       "Trainable params: 961\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#定义网络结构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input, fc1, fc2, fc3, y, out):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # 定义全连接层\n",
    "        self.fc1 = nn.Linear(input, fc1)\n",
    "        self.act1 = nn.Sigmoid()\n",
    "        \n",
    "        \"\"\"创建mask枝剪\n",
    "        #custom_mask = torch.randint(0, 2, size=self.fc1.weight.shape)\n",
    "        \n",
    "        custom_mask = torch.tensor([[1, 1, 0, 0],\n",
    "        [1, 0, 0, 0],\n",
    "        [1, 1, 0, 0],\n",
    "        [0, 1, 0, 0],\n",
    "        [0, 0, 1, 1],\n",
    "        [1, 0, 1, 0],\n",
    "        [1, 1, 1, 1],\n",
    "        [0, 1, 1, 0],\n",
    "        [1, 1, 0, 0],\n",
    "        [0, 0, 1, 0]])\n",
    "        print (custom_mask)\n",
    "        \n",
    "        prune.custom_from_mask(self.fc1, 'weight', mask=custom_mask)\n",
    "        \"\"\"\n",
    "\n",
    "        self.fc2 = nn.Linear(fc1, fc2)\n",
    "        self.act2 = nn.Sigmoid()\n",
    "\n",
    "        self.fc3 = nn.Linear(fc2, fc3)\n",
    "        self.act3 = nn.Sigmoid()\n",
    "\n",
    "        #self.y = nn.Linear(fc3, y)\n",
    "        \n",
    "        self.out = nn.Linear(fc3, out)\n",
    "        \n",
    "        \n",
    "        \"\"\"赋权重\n",
    "        w_init = torch.ones(self.fc4.weight.shape)\n",
    "        for i in range(len(w_init)):\n",
    "            for j in range(len(w_init[i])):\n",
    "                w_init[i][j] = float(random.randint(0, 1))\n",
    "        #w_init = torch.rand(self.fc4.weight.shape)\n",
    "        self.fc4.weight = Parameter(w_init)\n",
    "        \"\"\"\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.fc1(x))\n",
    "        x = self.act2(self.fc2(x))\n",
    "        x = self.act3(self.fc3(x))\n",
    "        #x = self.y(x)\n",
    "        x = self.out(x)\n",
    "        x = x.squeeze(-1)\n",
    "        return x \n",
    "\n",
    "# 构建网络\n",
    "net = Net(4, 20, 20, 20, 2, 1)\n",
    "\n",
    "\"\"\"\n",
    "#冻结层\n",
    "for name, param in net.named_parameters():\n",
    "    if \"y\" in name:\n",
    "        param.requires_grad = False\n",
    "\"\"\"        \n",
    "summary(net)\n",
    "#print (net.y.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('./data/ship_fuel_consumption_NN_1.csv')\n",
    "d = d.dropna(axis=0,how='any')\n",
    "d.to_csv('./data/ship_fuel_consumption_NN_2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShipDataset(Dataset):\n",
    "    \"\"\" 数据集演示 \"\"\"\n",
    "    def __init__(self, csv_file, x1, x2):\n",
    "        \"\"\"实现初始化方法，在初始化的时候将数据读载入\"\"\"\n",
    "        self.df = pd.read_csv(csv_file).iloc[x1:x2]\n",
    "        \n",
    "    def __len__(self):\n",
    "        '''\n",
    "        返回df的长度\n",
    "        '''\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        #data = ((self.df.iloc[idx].STW, self.df.iloc[idx].avgLEVEL, self.df.iloc[idx].headwind, self.df.iloc[idx].crosswind), self.df.iloc[idx].fuelConsumption)\n",
    "        input0 = torch.tensor(np.expand_dims(self.df.iloc[idx].STW, 0))\n",
    "        input1 = torch.tensor(np.expand_dims(self.df.iloc[idx].avgLEVEL, 0))\n",
    "        input2 = torch.tensor(np.expand_dims(self.df.iloc[idx].headwind, 0))\n",
    "        input3 = torch.tensor(np.expand_dims(self.df.iloc[idx].crosswind, 0))\n",
    "        data0 = torch.cat((input0, input1, input2, input3))\n",
    "        data1 = self.df.iloc[idx].fuelConsumption\n",
    "        tup = (data0, data1)\n",
    "        return tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165496"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ShipDataset('./data/ship_fuel_consumption_NN_2.csv', 0, int(len(d)*0.8))\n",
    "test = ShipDataset('./data/ship_fuel_consumption_NN_2.csv', int(len(d)*0.8), len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132396"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataLoader(train, batch_size=64, shuffle=True)\n",
    "test_data = DataLoader(test, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数--mse就是均方差\n",
    "criterion = nn.MSELoss()\n",
    "# 定义优化器---随机梯度下降\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Epoch-1-Batch-200: Train: Loss-0.010675, mae-0.070363,  rmse-0.103320\n",
      "[INFO] Epoch-1-Batch-400: Train: Loss-0.011347, mae-0.068789,  rmse-0.106524\n",
      "[INFO] Epoch-1-Batch-600: Train: Loss-0.012397, mae-0.073972,  rmse-0.111344\n",
      "[INFO] Epoch-1-Batch-800: Train: Loss-0.016461, mae-0.084343,  rmse-0.128302\n",
      "[INFO] Epoch-1-Batch-1000: Train: Loss-0.010202, mae-0.069488,  rmse-0.101006\n",
      "[INFO] Epoch-1-Batch-1200: Train: Loss-0.011758, mae-0.076150,  rmse-0.108433\n",
      "[INFO] Epoch-1-Batch-1400: Train: Loss-0.008276, mae-0.072199,  rmse-0.090975\n",
      "[INFO] Epoch-1-Batch-1600: Train: Loss-0.009613, mae-0.068366,  rmse-0.098048\n",
      "[INFO] Epoch-1-Batch-1800: Train: Loss-0.009927, mae-0.069813,  rmse-0.099632\n",
      "[INFO] Epoch-1-Batch-2000: Train: Loss-0.009709, mae-0.066176,  rmse-0.098534\n",
      "[INFO] Epoch-2-Batch-200: Train: Loss-0.011765, mae-0.076959,  rmse-0.108467\n",
      "[INFO] Epoch-2-Batch-400: Train: Loss-0.009182, mae-0.063422,  rmse-0.095824\n",
      "[INFO] Epoch-2-Batch-600: Train: Loss-0.007499, mae-0.064319,  rmse-0.086595\n",
      "[INFO] Epoch-2-Batch-800: Train: Loss-0.012193, mae-0.076715,  rmse-0.110423\n",
      "[INFO] Epoch-2-Batch-1000: Train: Loss-0.007274, mae-0.064243,  rmse-0.085285\n",
      "[INFO] Epoch-2-Batch-1200: Train: Loss-0.006383, mae-0.052568,  rmse-0.079892\n",
      "[INFO] Epoch-2-Batch-1400: Train: Loss-0.005457, mae-0.042212,  rmse-0.073875\n",
      "[INFO] Epoch-2-Batch-1600: Train: Loss-0.002920, mae-0.039885,  rmse-0.054034\n",
      "[INFO] Epoch-2-Batch-1800: Train: Loss-0.003992, mae-0.046551,  rmse-0.063183\n",
      "[INFO] Epoch-2-Batch-2000: Train: Loss-0.007503, mae-0.055572,  rmse-0.086618\n",
      "[INFO] Epoch-3-Batch-200: Train: Loss-0.005567, mae-0.048391,  rmse-0.074612\n",
      "[INFO] Epoch-3-Batch-400: Train: Loss-0.008537, mae-0.054941,  rmse-0.092395\n",
      "[INFO] Epoch-3-Batch-600: Train: Loss-0.003550, mae-0.036535,  rmse-0.059582\n",
      "[INFO] Epoch-3-Batch-800: Train: Loss-0.005416, mae-0.050058,  rmse-0.073591\n",
      "[INFO] Epoch-3-Batch-1000: Train: Loss-0.003017, mae-0.042775,  rmse-0.054924\n",
      "[INFO] Epoch-3-Batch-1200: Train: Loss-0.006664, mae-0.053035,  rmse-0.081631\n",
      "[INFO] Epoch-3-Batch-1400: Train: Loss-0.003924, mae-0.042013,  rmse-0.062641\n",
      "[INFO] Epoch-3-Batch-1600: Train: Loss-0.009408, mae-0.066951,  rmse-0.096994\n",
      "[INFO] Epoch-3-Batch-1800: Train: Loss-0.004754, mae-0.048114,  rmse-0.068951\n",
      "[INFO] Epoch-3-Batch-2000: Train: Loss-0.007770, mae-0.058589,  rmse-0.088149\n",
      "[INFO] Epoch-4-Batch-200: Train: Loss-0.001978, mae-0.031178,  rmse-0.044480\n",
      "[INFO] Epoch-4-Batch-400: Train: Loss-0.004860, mae-0.041251,  rmse-0.069710\n",
      "[INFO] Epoch-4-Batch-600: Train: Loss-0.006982, mae-0.051107,  rmse-0.083558\n",
      "[INFO] Epoch-4-Batch-800: Train: Loss-0.001847, mae-0.029262,  rmse-0.042976\n",
      "[INFO] Epoch-4-Batch-1000: Train: Loss-0.003191, mae-0.037473,  rmse-0.056493\n",
      "[INFO] Epoch-4-Batch-1200: Train: Loss-0.003891, mae-0.043983,  rmse-0.062381\n",
      "[INFO] Epoch-4-Batch-1400: Train: Loss-0.003183, mae-0.042030,  rmse-0.056418\n",
      "[INFO] Epoch-4-Batch-1600: Train: Loss-0.001691, mae-0.033921,  rmse-0.041118\n",
      "[INFO] Epoch-4-Batch-1800: Train: Loss-0.004053, mae-0.050244,  rmse-0.063662\n",
      "[INFO] Epoch-4-Batch-2000: Train: Loss-0.005349, mae-0.049097,  rmse-0.073137\n",
      "[INFO] Epoch-5-Batch-200: Train: Loss-0.005668, mae-0.064750,  rmse-0.075287\n",
      "[INFO] Epoch-5-Batch-400: Train: Loss-0.003691, mae-0.043083,  rmse-0.060752\n",
      "[INFO] Epoch-5-Batch-600: Train: Loss-0.003993, mae-0.043459,  rmse-0.063193\n",
      "[INFO] Epoch-5-Batch-800: Train: Loss-0.007375, mae-0.055297,  rmse-0.085877\n",
      "[INFO] Epoch-5-Batch-1000: Train: Loss-0.005859, mae-0.050226,  rmse-0.076545\n",
      "[INFO] Epoch-5-Batch-1200: Train: Loss-0.005429, mae-0.047491,  rmse-0.073680\n",
      "[INFO] Epoch-5-Batch-1400: Train: Loss-0.004363, mae-0.050103,  rmse-0.066052\n",
      "[INFO] Epoch-5-Batch-1600: Train: Loss-0.006399, mae-0.050222,  rmse-0.079993\n",
      "[INFO] Epoch-5-Batch-1800: Train: Loss-0.006333, mae-0.054384,  rmse-0.079582\n",
      "[INFO] Epoch-5-Batch-2000: Train: Loss-0.006238, mae-0.050451,  rmse-0.078983\n",
      "[INFO] Epoch-5: Train: Loss-0.004904 | Test: Loss-0.005119, mae-0.111387, rmse-0.144325\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "# 记录训练损失\n",
    "losses = []\n",
    "# 记录训练精度\n",
    "acces = []\n",
    "# 记录测试损失\n",
    "eval_losses = []\n",
    "# 记录测试精度\n",
    "eval_acces = []\n",
    "# 设置迭代次数\n",
    "nums_epoch = 5\n",
    "# 设置准确度小数点\n",
    "dot = 100\n",
    "\n",
    "for epoch in range(nums_epoch):\n",
    "    train_loss = 0\n",
    "    net = net.train()\n",
    "    for batch, (input, fuel) in enumerate(train_data):    \n",
    "        input = input.to(torch.float32)\n",
    "        fuel = fuel.to(torch.float32)\n",
    "        input = input.reshape(input.size(0), -1)    #标准化\n",
    "        input = Variable(input)    #包装张量，方便反向传播\n",
    "        fuel = Variable(fuel)\n",
    "\n",
    "        # 前向传播\n",
    "        out = net(input)\n",
    "        loss = criterion(out, fuel)\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 记录误差\n",
    "        train_loss += loss.item()\n",
    "        # 计算分类的准确率\n",
    "        pred = out\n",
    "        mae = mean_absolute_error(fuel.detach().numpy(), pred.detach().numpy())\n",
    "        rmse = np.sqrt(mean_squared_error(fuel.detach().numpy(), pred.detach().numpy()))\n",
    "            \n",
    "\n",
    "        if (batch + 1) % 200 == 0:\n",
    "            print('[INFO] Epoch-{}-Batch-{}: Train: Loss-{:.6f}, mae-{:.6f},  rmse-{:.6f}'.format(epoch + 1,\n",
    "                                                                                 batch+1,\n",
    "                                                                                 loss.item(),\n",
    "                                                                                 mae,\n",
    "                                                                                 rmse))\n",
    "    \n",
    "\n",
    "    losses.append(train_loss / len(train_data))\n",
    "\n",
    "    eval_loss = 0\n",
    "    \n",
    "    \n",
    "# 测试集不训练\n",
    "for batch, (input, fuel) in enumerate(test_data):     \n",
    "    input = input.to(torch.float32)\n",
    "    fuel = fuel.to(torch.float32)\n",
    "    input = input.reshape(input.size(0), -1)    \n",
    "    input = Variable(input)   \n",
    "    fuel = Variable(fuel)\n",
    "\n",
    "    # 前向传播\n",
    "    out = net(input)\n",
    "    loss = criterion(out, fuel)\n",
    "    # 记录误差\n",
    "    eval_loss += loss.item()\n",
    "\n",
    "    pred = out\n",
    "    mae = mean_absolute_error(fuel.detach().numpy(), pred.detach().numpy())\n",
    "    rmse = np.sqrt(mean_squared_error(fuel.detach().numpy(), pred.detach().numpy()))\n",
    "\n",
    "eval_losses.append(eval_loss / len(test_data))\n",
    "\n",
    "print('[INFO] Epoch-{}: Train: Loss-{:.6f} | Test: Loss-{:.6f}, mae-{:.6f}, rmse-{:.6f}'.format(\n",
    "    epoch + 1, train_loss / len(train_data), eval_loss / len(test_data), mae, rmse))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.suptitle('Test', fontsize=12)\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax1.plot(eval_losses, color='r')\n",
    "ax1.plot(losses, color='b')\n",
    "ax1.set_title('Loss', fontsize=10, color='black')\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax2.plot(eval_acces, color='r')\n",
    "ax2.plot(acces, color='b')\n",
    "ax2.set_title('Acc', fontsize=10, color='black')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
